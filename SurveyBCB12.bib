@misc{APS11,
  note = {Y.~Abbasi-Yadkori, D.~Pal, and C.~Szepesv\'ari. \newblock Improved algorithms for linear stochastic bandits. \newblock In \emph{Advances in Neural Information Processing Systems (NIPS)}, 2011.}
}

@misc{abe1999associative,
  note = {N.~Abe and P.M. Long. \newblock Associative reinforcement learning using linear probabilistic concepts. \newblock In \emph{Proceedings of the 16th International Conference on Machine Learning (ICML)}, 1999.}
}

@misc{AR09,
  note = {J.~Abernethy and A.~Rakhlin. \newblock Beating the adaptive bandit with high probability. \newblock In \emph{Proceedings of the 22nd Annual Conference on Learning Theory (COLT)}, 2009.}
}

@misc{AHR08,
  note = {J.~Abernethy, E.~Hazan, and A.~Rakhlin. \newblock Competing in the dark: An efficient algorithm for bandit linear optimization. \newblock In \emph{Proceedings of the 21st Annual Conference on Learning Theory (COLT)}, 2008.}
}

@misc{ABD10,
  note = {A.~Agarwal, P.~Bartlett, and M.~Dama. \newblock Optimal allocation strategies for the dark pool problem. \newblock In \emph{Proceedings of the 13th International Conference on Artificial Intelligence and Statistics (AISTATS)}, JMLR Workshop and Conference Proceedings Volume 9, 2010{\natexlab{a}}.}
}

@misc{ADX10,
  note = {A.~Agarwal, O.~Dekel, and L.~Xiao. \newblock Optimal algorithms for online convex optimization with multi-point bandit feedback. \newblock In \emph{Proceedings of the 23rd Annual Conference on Learning Theory (COLT)}, 2010{\natexlab{b}}.}
}

@misc{ADBL11,
  note = {A.~Agarwal, J.~Duchi, P.L. Bartlett, and C.~Levrard. \newblock Oracle inequalities for computationally budgeted model selection. \newblock In \emph{Proceedings of the 24th Annual Conference on Learning Theory (COLT)}, JMLR Workshop and Conference Proceedings Volume 19, 2011{\natexlab{a}}.}
}

@misc{agarwal2011stochastic,
  note = {A.~Agarwal, D.P. Foster, D.~Hsu, S.M. Kakade, and A.~Rakhlin. \newblock Stochastic convex optimization with bandit feedback. \newblock In \emph{Advances in Neural Information Processing Systems (NIPS)}, 2011{\natexlab{b}}.}
}

@misc{Agr95,
  note = {R.~Agrawal. \newblock Sample mean based index policies with $\mathcal{O}(\log n)$ regret for the multi-armed bandit problem. \newblock \emph{Advances in Applied Mathematics}, 27:\penalty0 1054--1078, 1995.}
}

@misc{AG12,
  note = {S.~Agrawal and N.~Goyal. \newblock Analysis of {T}hompson sampling for the multi-armed bandit problem. \newblock In \emph{Proceedings of the 25th Annual Conference on Learning Theory (COLT)}, JMLR Workshop and Conference Proceedings Volume 23, 2012.}
}

@misc{AAGO06,
  note = {C.~Allenberg, P.~Auer, L.~Gy{\"{o}}rfi, and G.~Ottucs{\'{a}}k. \newblock {H}annan consistency in on-line learning in case of unbounded losses under partial monitoring. \newblock In \emph{Proceedings of the 17th International Conference on Algorithmic Learning Theory (ALT)}, 2006.}
}

@misc{AKS11,
  note = {K.~Amin, M.~Kearns, and U.~Syed. \newblock Bandits, query learning, and the haystack dimension. \newblock In \emph{Proceedings of the 24th Annual Conference on Learning Theory (COLT)}, JMLR Workshop and Conference Proceedings Volume 19, 2011.}
}

@misc{AGS08,
  note = {A.~Antos, V.~Grover, and C.~Szepesv\'ari. \newblock Active learning in multi-armed bandits. \newblock In \emph{Proceedings of the 19th International Conference on Algorithmic Learning Theory (ALT)}, 2008.}
}

@misc{arora2012online,
  note = {R.~Arora, O.~Dekel, and A.~Tewari. \newblock Online bandit learning against an adaptive adversary: from regret to policy regret. \newblock In \emph{Proceedings of the 29th International Conference on Machine Learning (ICML)}, 2012{\natexlab{a}}.}
}

@misc{arora2012multiplicative,
  note = {S.~Arora, E.~Hazan, and S.~Kale. \newblock The multiplicative weights update method: A meta-algorithm and applications. \newblock \emph{Theory of Computing}, 8:\penalty0 121--164, 2012{\natexlab{b}}.}
}

@misc{arrow1949bayes,
  note = {K.J. Arrow, D.~Blackwell, and M.A. Girshick. \newblock Bayes and minimax solutions of sequential decision problems. \newblock \emph{Econometrica}, pages 213--244, 1949.}
}

@misc{AB09,
  note = {J.-Y. Audibert and S.~Bubeck. \newblock Minimax policies for adversarial and stochastic bandits. \newblock In \emph{Proceedings of the 22nd Annual Conference on Learning Theory (COLT)}, 2009.}
}

@misc{AB10,
  note = {J.-Y. Audibert and S.~Bubeck. \newblock Regret bounds and minimax policies under partial monitoring. \newblock \emph{Journal of Machine Learning Research}, 11:\penalty0 2635--2686, 2010.}
}

@misc{AMS09,
  note = {J.-Y. Audibert, R.~Munos, and C.~Szepesv\'ari. \newblock Exploration-exploitation trade-off using variance estimates in multi-armed bandits. \newblock \emph{Theoretical Computer Science}, 410:\penalty0 1876--1902, 2009.}
}

@misc{ABM10,
  note = {J.-Y. Audibert, S.~Bubeck, and R.~Munos. \newblock Best arm identification in multi-armed bandits. \newblock In \emph{Proceedings of the 23rd Annual Conference on Learning Theory (COLT)}, 2010.}
}

@misc{ABL11,
  note = {J.-Y. Audibert, S.~Bubeck, and G.~Lugosi. \newblock Minimax policies for combinatorial prediction games. \newblock In \emph{Proceedings of the 24th Annual Conference on Learning Theory (COLT)}, JMLR Workshop and Conference Proceedings Volume 19, 2011.}
}

@misc{Aue02,
  note = {P.~Auer. \newblock Using confidence bounds for exploitation-exploration trade-offs. \newblock \emph{Journal of Machine Learning Research}, 3:\penalty0 397--422, 2002.}
}

@misc{AO10,
  note = {P.~Auer and R.~Ortner. \newblock {UCB} revisited: Improved regret bounds for the stochastic multi-armed bandit problem. \newblock \emph{Periodica Mathematica Hungarica}, 61:\penalty0 55--65, 2010.}
}

@misc{ACF02,
  note = {P.~Auer, N.~Cesa-Bianchi, and P.~Fischer. \newblock Finite-time analysis of the multiarmed bandit problem. \newblock \emph{Machine Learning Journal}, 47\penalty0 (2-3):\penalty0 235--256, 2002{\natexlab{a}}.}
}

@misc{ACFS03,
  note = {P.~Auer, N.~Cesa-Bianchi, Y.~Freund, and R.~Schapire. \newblock The non-stochastic multi-armed bandit problem. \newblock \emph{SIAM Journal on Computing}, 32\penalty0 (1):\penalty0 48--77, 2002{\natexlab{b}}.}
}

@misc{auer2007improved,
  note = {P.~Auer, R.~Ortner, and C.~Szepesv{\'a}ri. \newblock Improved rates for the stochastic continuum-armed bandit problem. \newblock In \emph{Proceedings of the 20th International Conference on Learning Theory (COLT)}, 2007.}
}

@misc{AK04,
  note = {B.~Awerbuch and R.~Kleinberg. \newblock Adaptive routing with end-to-end feedback: distributed learning and geometric approaches. \newblock In \emph{Proceedings of the thirty-sixth annual ACM symposium on Theory of computing (STOC)}, 2004.}
}

@misc{BSS09,
  note = {M.~Babaioff, Y.~Sharma, and A.~Slivkins. \newblock Characterizing truthful multi-armed bandit mechanisms,. \newblock In \emph{ACM Conference on Electronic Commerce 2009 (EC)}, 2009.}
}

@misc{BKS10,
  note = {M.~Babaioff, R.D. Kleinberg, and A.~Slivkins. \newblock Truthful mechanisms with implicit payment computation. \newblock In \emph{ACM Conference on Electronic Commerce 2010 (EC)}, 2010.}
}

@misc{BM11,
  note = {F.~Bach and E.~Moulines. \newblock Non-asymptotic analysis of stochastic approximation algorithms for machine learning. \newblock In \emph{Advances in Neural Information Processing Systems (NIPS)}, 2011.}
}

@misc{Bal97,
  note = {K.~Ball. \newblock An elementary introduction to modern convex geometry. \newblock In S.~Levy, editor, \emph{Flavors of Geometry}, pages 1--58. Cambridge University Press, 1997.}
}

@misc{Ban68,
  note = {A.~Ba{\~n}os. \newblock On pseudo-games. \newblock \emph{Annals of Mathematical Statistics}, 39:\penalty0 1932--1945, 1968.}
}

@misc{BDHKRT08,
  note = {P.~Bartlett, V.~Dani, T.~Hayes, S.~Kakade, A.~Rakhlin, and A.~Tewari. \newblock High probability regret bounds for online optimization. \newblock In \emph{Proceedings of the 21st Annual Conference on Learning Theory (COLT)}, 2008.}
}

@misc{BPS10,
  note = {G.~Bartok, D.~Pal, and C.~Szepesv\'ari. \newblock Toward a classification of finite partial-monitoring games. \newblock In \emph{Proceedings of the 21st International Conference on Algorithmic Learning Theory (ALT)}, 2010.}
}

@misc{BPSS11,
  note = {G.~Bartok, D.~Pal, C.~Szepesv\'ari, and I.~Szita. \newblock Online learning. \newblock Lecture Notes, 2011.}
}

@misc{BT03,
  note = {A.~Beck and M.~Teboulle. \newblock {M}irror {D}escent and nonlinear projected subgradient methods for convex optimization. \newblock \emph{Operations Research Letters}, 31\penalty0 (3):\penalty0 167--175, 2003.}
}

@misc{BN99,
  note = {A.~Ben-Tal and A.~Nemirovski. \newblock The conjugate barrier {M}irror {D}escent method for non-smooth convex optimization. \newblock Technical report, MINERVA Optimization Center Report, Faculty of Industrial Engineering and Management, Technion--Israel Institute of Technology, Haifa, 1999.}
}

@misc{BCZHS97,
  note = {D.A. Berry, R.W. Chen, D.C.~Heath A.~Zame, and L.A. Shepp. \newblock Bandit problems with infinitely many arms. \newblock \emph{Annals of Statistics}, 25:\penalty0 2103--2116, 1997.}
}

@misc{beygelzimer2011contextual,
  note = {A.~Beygelzimer, J.~Langford, L.~Li, L.~Reyzin, and R.~Schapire. \newblock Contextual bandit algorithms with supervised learning guarantees. \newblock In \emph{Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics (AISTATS)}, JMLR Workshop and Conference Proceedings Volume 15, 2011{\natexlab{a}}.}
}

@misc{beygelzimer2010contextual,
  note = {A.~Beygelzimer, J.~Langford, L.~Li, L.~Reyzin, and R.E. Schapire. \newblock Contextual bandit algorithms with supervised learning guarantees. \newblock In \emph{Proceedings of the 15th International Conference on Artificial Intelligence and Statistics (AISTATS)}, JMLR Workshop and Conference Proceedings Volume 15, 2011{\natexlab{b}}.}
}

@misc{BBL05,
  note = {S.~Boucheron, O.~Bousquet, and G.~Lugosi. \newblock Theory of classification: a survey of recent advances. \newblock \emph{ESAIM: Probability and Statistics}, 9:\penalty0 323--375, 2005.}
}

@misc{BV04,
  note = {S.~Boyd and L.~Vandenberghe. \newblock \emph{Convex Optimization}. \newblock Cambridge University Press, 2004.}
}

@misc{Bub10,
  note = {S.~Bubeck. \newblock \emph{Bandits Games and Clustering Foundations}. \newblock PhD thesis, Universit\'e Lille 1, 2010.}
}

@misc{Bub11,
  note = {S.~Bubeck. \newblock Introduction to online optimization. \newblock Lecture Notes, 2011.}
}

@misc{BM10,
  note = {S.~Bubeck and R.~Munos. \newblock Open loop optimistic planning. \newblock In \emph{Proceedings of the 23rd Annual Conference on Learning Theory (COLT)}, 2010.}
}

@misc{BS12,
  note = {S.~Bubeck and A.~Slivkins. \newblock The best of both worlds: stochastic and adversarial bandits. \newblock In \emph{Proceedings of the 25th Annual Conference on Learning Theory (COLT)}, JMLR Workshop and Conference Proceedings Volume 23, 2012.}
}

@misc{BMS09,
  note = {S.~Bubeck, R.~Munos, and G.~Stoltz. \newblock Pure exploration in multi-armed bandits problems. \newblock In \emph{Proceedings of the 20th International Conference on Algorithmic Learning Theory (ALT)}, 2009{\natexlab{a}}.}
}

@misc{BMSS09,
  note = {S.~Bubeck, R.~Munos, G.~Stoltz, and C.~Szepesv\'ari. \newblock Online optimization in $\mathcal{X}$-armed bandits. \newblock In \emph{Advances in Neural Information Processing Systems (NIPS)}, 2009{\natexlab{b}}.}
}

@misc{BEG11,
  note = {S.~Bubeck, D.~Ernst, and A.~Garivier. \newblock Optimal discovery with probabilistic expert advice. \newblock \emph{Arxiv preprint arXiv:1110.5447}, 2011{\natexlab{a}}.}
}

@misc{BMS11,
  note = {S.~Bubeck, R.~Munos, and G.~Stoltz. \newblock Pure exploration in finitely-armed and continuously-armed bandits. \newblock \emph{Theoretical Computer Science}, 412:\penalty0 1832--1852, 2011{\natexlab{b}}.}
}

@misc{BMSS11,
  note = {S.~Bubeck, R.~Munos, G.~Stoltz, and C.~Szepesv\'ari. \newblock $\mathcal{X}$-armed bandits. \newblock \emph{Journal of Machine Learning Research}, 12:\penalty0 1587--1627, 2011{\natexlab{c}}.}
}

@misc{BCK12,
  note = {S.~Bubeck, N.~Cesa-Bianchi, and S.M. Kakade. \newblock Towards minimax policies for online linear optimization with bandit feedback. \newblock In \emph{Proceedings of the 25th Annual Conference on Learning Theory (COLT)}, JMLR Workshop and Conference Proceedings Volume 23, 2012{\natexlab{a}}.}
}

@misc{BCL12,
  note = {S.~Bubeck, N.~Cesa-Bianchi, and G.~Lugosi. \newblock Bandits with heavy tail. \newblock \emph{Arxiv preprint arXiv:1209.1727}, 2012{\natexlab{b}}.}
}

@misc{BWV12,
  note = {S.~Bubeck, T.~Wang, and N.~Viswanathan. \newblock Multiple identifications in multi-armed bandits. \newblock \emph{Arxiv preprint arXiv:1205.3181}, 2012{\natexlab{c}}.}
}

@misc{BJM11,
  note = {L.~Bui, R.~Johari, and S.~Mannor. \newblock Committing bandits. \newblock In \emph{Advances in Neural Information Processing Systems (NIPS)}, 2011.}
}

@misc{BK97,
  note = {A.N. Burnetas and M.N. Katehakis. \newblock Optimal adaptive policies for {M}arkov decision processes. \newblock \emph{Mathematics of Operations Research}, pages 222--255, 1997.}
}

@misc{BK11,
  note = {R.~Busa{-}Fekete and B.~Kegl. \newblock Fast boosting using adversarial bandits. \newblock In \emph{Proceedings of the 28th International Conference on Machine Learning (ICML)}, 2011.}
}

@misc{CGMMS12,
  note = {O.~Capp{\'e}, A.~Garivier, O.~Maillard, R.~Munos, and G.~Stoltz. \newblock {K}ullback-{L}eibler upper confidence bounds for optimal sequential allocation. \newblock \emph{Arxiv preprint arXiv:1210.1136}, 2012.}
}

@misc{CM11,
  note = {A.~Carpentier and R.~Munos. \newblock Finite time analysis of stratified sampling for monte carlo. \newblock In \emph{Advances in Neural Information Processing Systems (NIPS)}, 2011.}
}

@misc{CLGMA11,
  note = {A.~Carpentier, A.~Lazaric, M.~Ghavamzadeh, R.~Munos, and P.~Auer. \newblock Upper confidence bounds algorithms for active learning in multi-armed bandits. \newblock In \emph{Proceedings of the 22nd International Conference on Algorithmic Learning Theory (ALT)}, 2011.}
}

@misc{CL06,
  note = {N.~Cesa-Bianchi and G.~Lugosi. \newblock \emph{Prediction, Learning, and Games}. \newblock Cambridge University Press, 2006.}
}

@misc{CL11,
  note = {N.~Cesa-Bianchi and G.~Lugosi. \newblock Combinatorial bandits. \newblock \emph{Journal of Computer and System Sciences}, 78\penalty0 (5):\penalty0 1404--1422, 2012.}
}

@misc{CLS05,
  note = {N.~Cesa-Bianchi, G.~Lugosi, and G.~Stoltz. \newblock Minimizing regret with label efficient prediction. \newblock \emph{IEEE Transactions on Information Theory}, 51:\penalty0 2152--2162, 2005.}
}

@misc{CMS07,
  note = {N.~Cesa-Bianchi, Y.~Mansour, and G.~Stoltz. \newblock Improved second-order bounds for prediction with expert advice. \newblock \emph{Machine Learning}, 66:\penalty0 321--352, 2007.}
}

@misc{CLi11,
  note = {O.~Chapelle and L.~Li. \newblock An empirical evaluation of {T}hompson sampling. \newblock In \emph{Advances in Neural Information Processing Systems (NIPS)}, 2011.}
}

@misc{chu2011contextual,
  note = {W.~Chu, L.~Li, L.~Reyzin, and R.~Schapire. \newblock Contextual bandits with linear payoff functions. \newblock \emph{JMLR Workshop and Conference Proceedings Volume 15}, 2011.}
}

@misc{CSV09,
  note = {A.~Conn, K.~Scheinberg, and L.~Vicente. \newblock \emph{Introduction to Derivative-Free Optimization}. \newblock Society for Industrial and Applied Mathematics (SIAM), 2009.}
}

@misc{cope2009regret,
  note = {E.W. Cope. \newblock Regret and convergence bounds for a class of continuum-armed bandit problems. \newblock \emph{IEEE Transactions on Automatic Control}, 54\penalty0 (6):\penalty0 1243--1253, 2009.}
}

@misc{CM07,
  note = {P.-A. Coquelin and R.~Munos. \newblock Bandit algorithms for tree search. \newblock In \emph{Proceedings of the 23rd Conference on Uncertainty in Artificial Intelligence (UAI)}, 2007.}
}

@misc{crammer2011multiclass,
  note = {K.~Crammer and C.~Gentile. \newblock Multiclass classification with bandit feedback using adaptive regularization. \newblock In \emph{Proceedings of the 28th International Conference on Machine Learning (ICML)}, 2011.}
}

@misc{DHK08,
  note = {V.~Dani, T.~Hayes, and S.~Kakade. \newblock {The price of bandit information for online optimization}. \newblock In \emph{Advances in Neural Information Processing Systems (NIPS)}, 2008{\natexlab{a}}.}
}

@misc{DHK08b,
  note = {V.~Dani, T.~Hayes, and S.~Kakade. \newblock Stochastic linear optimization under bandit feedback. \newblock In \emph{Proceedings of the 21st Annual Conference on Learning Theory (COLT)}, 2008{\natexlab{b}}.}
}

@misc{DK09,
  note = {N.~Devanur and S.M. Kakade. \newblock The price of truthfulness for pay-per-click auctions. \newblock In \emph{ACM Conference on Electronic Commerce 2009 (EC)}, 2009.}
}

@misc{dudik2011efficient,
  note = {M.~Dudik, D.~Hsu, S.~Kale, N.~Karampatziakis, J.~Langford, L.~Reyzin, and T.~Zhang. \newblock Efficient optimal learning for contextual bandits. \newblock In \emph{Proceedings of the 27th Conference on Uncertainty in Artificial Intelligence (UAI)}, 2011.}
}

@misc{EMM02,
  note = {E.~Even-Dar, S.~Mannor, and Y.~Mansour. \newblock Pac bounds for multi-armed bandit and markov decision processes. \newblock In \emph{Proceedings of the Fifteenth Annual Conference on Computational Learning Theory (COLT)}, 2002.}
}

@misc{EMM06,
  note = {E.~Even-Dar, S.~Mannor, and Y.~Mansour. \newblock Action elimination and stopping conditions for the multi-armed bandit and reinforcement learning problems. \newblock \emph{Journal of Machine Learning Research}, 7:\penalty0 1079--1105, 2006.}
}

@misc{filippi2010parametric,
  note = {S.~Filippi, O.~Capp{\'e}, A.~Garivier, and C.~Szepesv{\'a}ri. \newblock Parametric bandits: The generalized linear case. \newblock In \emph{Neural Information Processing Systems (NIPS)}, 2010.}
}

@misc{filippi2011optimally,
  note = {S.~Filippi, O.~Capp{\'e}, and A.~Garivier. \newblock Optimally sensing a single channel without prior information: The tiling algorithm and regret bounds. \newblock \emph{Selected Topics in Signal Processing}, 5\penalty0 (1):\penalty0 68--76, 2011.}
}

@misc{FKM05,
  note = {A.~Flaxman, A.~Kalai, and B.~McMahan. \newblock Online convex optimization in the bandit setting: Gradient descent without a gradient. \newblock In \emph{In Proceedings of the Sixteenth Annual ACM-SIAM Symposium on Discrete Algorithms (SODA)}, 2005.}
}

@misc{FR11,
  note = {D.~Foster and A.~Rakhlin. \newblock No internal regret via neighborhood watch. \newblock In \emph{Proceedings of the 15th International Conference on Artificial Intelligence and Statistics (AISTATS)}, JMLR Workshop and Conference Proceedings Volume 22, 2012.}
}

@misc{FoVo98,
  note = {D.~Foster and R.~Vohra. \newblock Asymptotic calibration. \newblock \emph{Biometrika}, 85:\penalty0 379--390, 1998.}
}

@misc{GGLB11,
  note = {V.~Gabillon, M.~Ghavamzadeh, A.~Lazaric, and S.~Bubeck. \newblock Multi-bandit best arm identification. \newblock In \emph{Advances in Neural Information Processing Systems (NIPS)}, 2011.}
}

@misc{GC11,
  note = {A.~Garivier and O.~Capp\'e. \newblock The {KL-UCB} algorithm for bounded stochastic bandits and beyond. \newblock In \emph{Proceedings of the 24th Annual Conference on Learning Theory (COLT)}, JMLR Workshop and Conference Proceedings Volume 19, 2011.}
}

@misc{GM11,
  note = {A.~Garivier and E.~Moulines. \newblock On upper-confidence bound policies for switching bandit problems. \newblock In \emph{Proceedings of the 22nd International Conference on Algorithmic Learning Theory (ALT)}, 2011.}
}

@misc{GWMT06,
  note = {S.~Gelly, Y.~Wang, R.~Munos, and O.~Teytaud. \newblock Modification of {UCT} with patterns in {M}onte-{C}arlo {G}o. \newblock Technical Report RR-6062, INRIA, 2006.}
}

@misc{GGW11,
  note = {J.~Gittins, K.~Glazebrook, and R.~Weber. \newblock \emph{Multi-Armed Bandit Allocation Indices (2nd edition)}. \newblock John Wiley and Sons, 2011.}
}

@misc{gittins1979bandit,
  note = {J.C. Gittins. \newblock Bandit processes and dynamic allocation indices. \newblock \emph{Journal of the Royal Statistical Society. Series B (Methodological)}, pages 148--177, 1979.}
}

@misc{GLS01,
  note = {A.~Grove, N.~Littlestone, and D.~Schuurmans. \newblock General convergence results for linear discriminant updates. \newblock \emph{Machine Learning}, 43:\penalty0 173--210, 2001.}
}

@misc{GAOS10,
  note = {S.~Gr\"unew\"alder, J.-Y. Audibert, M.~Opper, and J.~Shawe-Taylor. \newblock Regret bounds for {G}aussian process bandit problems. \newblock In \emph{Proceedings of the 13th International Conference on Artificial Intelligence and Statistics (AISTATS)}, JMLR Workshop and Conference Proceedings Volume 9, 2010.}
}

@misc{GKSS07,
  note = {A.~Gy{\"o}rgy, L.~Kocsis, I.~Szab{\'o}, and C.~Szepesv{\'a}ri. \newblock Continuous time associative bandit problems. \newblock In \emph{Proceedings of the 20th International Joint Conference on Artificial Intelligence (IJCAI)}, 2007.}
}

@misc{GLLO07,
  note = {A.~Gy\"{o}rgy, T.~Linder, G.~Lugosi, and G.~Ottucs\'{a}k. \newblock The on-line shortest path problem under partial monitoring. \newblock \emph{Journal of Machine Learning Research}, 8:\penalty0 2369--2403, 2007.}
}

@misc{Han57,
  note = {J.~Hannan. \newblock Approximation to {B}ayes risk in repeated play. \newblock \emph{Contributions to the theory of games}, 3:\penalty0 97--139, 1957.}
}

@misc{HaMa99,
  note = {S.~Hart and A.~Mas-Colell. \newblock A simple adaptive procedure leading to correlated equilibrium. \newblock \emph{Econometrica}, 68:\penalty0 1127--1150, 2000.}
}

@misc{HaMa00,
  note = {S.~Hart and A.~Mas-Colell. \newblock A general class of adaptive strategies. \newblock \emph{Journal of Economic Theory}, 98:\penalty0 26--54, 2001.}
}

@misc{Haz11,
  note = {E.~Hazan. \newblock The convex optimization approach to regret minimization. \newblock In S.~Sra, S.~Nowozin, and S.~Wright, editors, \emph{Optimization for Machine Learning}, pages 287--303. MIT press, 2011.}
}

@misc{HK09,
  note = {E.~Hazan and S.~Kale. \newblock Better algorithms for benign bandits. \newblock In \emph{Proceedings of the 20th Annual ACM-SIAM Symposium on Discrete Algorithms (SODA)}, pages 38--47, 2009.}
}

@misc{hazan2011newtron,
  note = {E.~Hazan and S.~Kale. \newblock {NEWTRON}: an efficient bandit algorithm for online multiclass prediction. \newblock In \emph{Advances in Neural Information Processing Systems (NIPS)}, 2011.}
}

@misc{HKW10,
  note = {E.~Hazan, S.~Kale, and M.~Warmuth. \newblock Learning rotations with little regret. \newblock In \emph{Proceedings of the 23rd Annual Conference on Learning Theory (COLT)}, 2010.}
}

@misc{HP97,
  note = {D.~Helmbold and S.~Panizza. \newblock {Some label efficient learning results}. \newblock In \emph{Proceedings of the 10th Annual Conference on Computational Learning Theory (COLT)}, 1997.}
}

@misc{HW09,
  note = {D.P. Helmbold and M.~Warmuth. \newblock Learning permutations with exponential weights. \newblock \emph{Journal of Machine Learning Research}, 10:\penalty0 1705--1736, 2009.}
}

@misc{HW98,
  note = {M.~Herbster and M.~Warmuth. \newblock Tracking the best expert. \newblock \emph{Machine Learning}, 32:\penalty0 151--178, 1998.}
}

@misc{HL01,
  note = {J.-B. Hiriart-Urruty and C.~Lemar{\'e}chal. \newblock \emph{Fundamentals of Convex Analysis}. \newblock Springer, 2001.}
}

@misc{HT10,
  note = {J.~Honda and A.~Takemura. \newblock An asymptotically optimal bandit algorithm for bounded support models. \newblock In \emph{Proceedings of the 23rd Annual Conference on Learning Theory (COLT)}, 2010.}
}

@misc{HT10b,
  note = {J.-B. Hoock and O.~Teytaud. \newblock Bandit-based genetic programming. \newblock In \emph{Proceedings of the 13th European Conference on Genetic Programming (EuroGP)}, 2010.}
}

@misc{JOA10,
  note = {T.~Jaksch, R.~Ortner, and P.~Auer. \newblock Near-optimal regret bounds for reinforcement learning. \newblock \emph{Journal of Machine Learning Research}, 11:\penalty0 1563--1600, 2010.}
}

@misc{JNTV05,
  note = {A.~Juditsky, A.~Nazin, A.~Tsybakov, and N.~Vayatis. \newblock Recursive aggregation of estimators by the {M}irror {D}escent algorithm with averaging. \newblock \emph{Problems of Information Transmission}, 41:\penalty0 368--384, 2005.}
}

@misc{KST10,
  note = {S.~Kakade, S.~Shalev-Shwartz, and A.~Tewari. \newblock Regularization techniques for learning with matrices. \newblock \emph{Journal of Machine Learning Research}, 13:\penalty0 1865--1890, 2012.}
}

@misc{Kak03,
  note = {S.M. Kakade. \newblock \emph{On the Sample Complexity of Reinforcement Learning}. \newblock PhD thesis, Gatsby Computational Neuroscience Unit, University College London, 2003.}
}

@misc{kakade2008efficient,
  note = {S.M. Kakade, S.~Shalev-Shwartz, and A.~Tewari. \newblock Efficient bandit algorithms for online multiclass prediction. \newblock In \emph{Proceedings of the 25th International Conference on Machine Learning (ICML)}, 2008.}
}

@misc{KV05,
  note = {A.~Kalai and S.~Vempala. \newblock Efficient algorithms for online decision problems. \newblock \emph{Journal of Computer and System Sciences}, 71:\penalty0 291--307, 2005.}
}

@misc{KRS10,
  note = {S.~Kale, L.~Reyzin, and R.~Schapire. \newblock Non-stochastic bandit slate problems. \newblock In \emph{Advances in Neural Information Processing Systems (NIPS)}, 2010.}
}

@misc{KS12,
  note = {V.~Kanade and T.~Steinke. \newblock Learning hurdles for sleeping experts. \newblock In \emph{Proceedings of the 3rd Innovations in Theoretical Computer Science Conference}. ACM, 2012.}
}

@misc{KMB09,
  note = {V.~Kanade, B.~McMahan, and B.~Bryan. \newblock Sleeping experts and bandits with stochastic action availability and adversarial rewards. \newblock In \emph{Proceedings of the 12th International Conference on Artificial Intelligence and Statistics (AISTATS)}, JMLR Workshop and Conference Proceedings Volume 5, 2009.}
}

@misc{KCG12,
  note = {E.~Kaufmann, O.~Capp{\'e}, and A.~Garivier. \newblock On {B}ayesian upper confidence bounds for bandits problems. \newblock In \emph{Proceedings of the 15th International Conference on Artificial Intelligence and Statistics (AISTATS)}, JMLR Workshop and Conference Proceedings Volume 22, 2012{\natexlab{a}}.}
}

@misc{KKM12,
  note = {E.~Kaufmann, N.~Korda, and R.~Munos. \newblock {T}hompson sampling: an asymptotically optimal finite-time analysis. \newblock In \emph{Proceedings of the 23rd International Conference on Algorithmic Learning Theory (ALT)}, 2012{\natexlab{b}}.}
}

@misc{KMN02,
  note = {M.~Kearns, Y.~Mansour, and A.Y. Ng. \newblock A sparse sampling algorithm for near-optimal planning in large {M}arkovian decision processes. \newblock \emph{Machine Learning}, 49:\penalty0 193--208, 2002.}
}

@misc{kiefer1953sequential,
  note = {J.~Kiefer. \newblock Sequential minimax search for a maximum. \newblock \emph{Proceedings of the American Mathematical Society}, 4\penalty0 (3):\penalty0 502--506, 1953.}
}

@misc{KW52,
  note = {J.~Kiefer and J.~Wolfowitz. \newblock Stochastic estimation of the maximum of a regression function. \newblock \emph{Annals of Mathematical Statistics}, 23:\penalty0 462--466, 1952.}
}

@misc{KW01,
  note = {J.~Kivinen and M.~Warmuth. \newblock Relative loss bounds for multidimensional regression problems. \newblock \emph{Machine Learning}, 45:\penalty0 301--329, 2001.}
}

@misc{kleinberg2004nearly,
  note = {R.~Kleinberg. \newblock Nearly tight bounds for the continuum-armed bandit problem. \newblock \emph{Advances in Neural Information Processing Systems (NIPS)}, 2004.}
}

@misc{KSU08,
  note = {R.~Kleinberg, A.~Slivkins, and E.~Upfal. \newblock Multi-armed bandits in metric spaces. \newblock In \emph{Proceedings of the 40th ACM Symposium on Theory of Computing (STOC)}, 2008.}
}

@misc{KNS10,
  note = {R.~Kleinberg, A.~Niculescu-Mizil, and Y.~Sharma. \newblock Regret bounds for sleeping experts and bandits. \newblock \emph{Machine Learning}, 80:\penalty0 245--272, 2010.}
}

@misc{KS06,
  note = {L.~Kocsis and C.~Szepesv\'ari. \newblock Bandit based {M}onte-{C}arlo planning. \newblock In \emph{Proceedings of the 15th European Conference on Machine Learning (ECML)}, 2006.}
}

@misc{KWK10,
  note = {W.~Koolen, M.~Warmuth, and J.~Kivinen. \newblock Hedging structured concepts. \newblock In \emph{Proceedings of the 23rd Annual Conference on Learning Theory (COLT)}, 2010.}
}

@misc{LR85,
  note = {T.~L. Lai and H.~Robbins. \newblock Asymptotically efficient adaptive allocation rules. \newblock \emph{Advances in Applied Mathematics}, 6:\penalty0 4--22, 1985.}
}

@misc{langford2007epoch,
  note = {J.~Langford and T.~Zhang. \newblock The epoch-greedy algorithm for contextual multi-armed bandits. \newblock \emph{Advances in Neural Information Processing Systems (NIPS)}, 2007.}
}

@misc{Lez98,
  note = {P.~Lezaud. \newblock {C}hernoff-type bound for finite {M}arkov chains. \newblock \emph{Annals of Applied Probability}, 8:\penalty0 849--867, 1998.}
}

@misc{li2010contextual,
  note = {L.~Li, W.~Chu, J.~Langford, and R.E. Schapire. \newblock A contextual-bandit approach to personalized news article recommendation. \newblock In \emph{Proceedings of the 19th International Conference on World Wide Web (WWW)}, 2010.}
}

@misc{LZK10,
  note = {K.~Liu, Q.~Zhao, and B.~Krishnamachari. \newblock Dynamic multichannel access with imperfect channel state detection. \newblock \emph{IEEE Transactions on Signal Processing}, 58:\penalty0 2795--2808, 2010.}
}

@misc{mahajan2008multi,
  note = {A.~Mahajan and D.~Teneketzis. \newblock Multi-armed bandit problems. \newblock In \emph{Foundations and Applications of Sensor Management}, pages 121--151. Springer, 2008.}
}

@misc{maillard2011adaptive,
  note = {O.~Maillard and R.~Munos. \newblock Adaptive bandits: Towards the best history-dependent strategy. \newblock In \emph{Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics (AISTATS)}, JMLR Workshop and Conference Proceedings Volume 15, 2011.}
}

@misc{MMS11,
  note = {O.-A. Maillard, R.~Munos, and G.~Stoltz. \newblock A finite-time analysis of multi-armed bandits problems with {K}ullback-{L}eibler divergences. \newblock In \emph{Proceedings of the 24th Annual Conference on Learning Theory (COLT)}, JMLR Workshop and Conference Proceedings Volume 19, 2011.}
}

@misc{MS11,
  note = {S.~Mannor and O.~Shamir. \newblock From bandits to experts: On the value of side-observations. \newblock In \emph{Advances in Neural Information Processing Systems (NIPS)}, 2011.}
}

@misc{MT04,
  note = {S.~Mannor and J.~N. Tsitsiklis. \newblock The sample complexity of exploration in the multi-armed bandit problem. \newblock \emph{Journal of Machine Learning Research}, 5:\penalty0 623--648, 2004.}
}

@misc{MB04,
  note = {H.~McMahan and A.~Blum. \newblock Online geometric optimization in the bandit setting against an adaptive adversary. \newblock In \emph{In Proceedings of the 17th Annual Conference on Learning Theory (COLT)}, 2004.}
}

@misc{mcmahan2009tighter,
  note = {H.B. McMahan and M.~Streeter. \newblock Tighter bounds for multi-armed bandits with expert advice. \newblock In \emph{Proceedings of the 22nd International Conference on Learning Theory (COLT)}, 2009.}
}

@misc{Nem79,
  note = {A.~Nemirovski. \newblock Efficient methods for large-scale convex optimization problems. \newblock \emph{Ekonomika i Matematicheskie Metody}, 15, 1979. \newblock (In Russian).}
}

@misc{NY83,
  note = {A.~Nemirovski and D.~Yudin. \newblock \emph{Problem Complexity and Method Efficiency in Optimization}. \newblock Wiley Interscience, 1983.}
}

@misc{NJLS09,
  note = {A.~Nemirovski, A.~Juditsky, G.~Lan, and A.~Shapiro. \newblock Robust stochastic approximation approach to stochastic programming. \newblock \emph{SIAM Journal on Optimization}, 19:\penalty0 1574--1609, 2009.}
}

@misc{Nes11,
  note = {Y.~Nesterov. \newblock Random gradient-free minimization of convex functions. \newblock Core discussion papers, Universit{\'e} catholique de Louvain, Center for Operations Research and Econometrics (CORE), 2011.}
}

@misc{NGSA10,
  note = {G.~Neu, A.~Gyorgy, C.~Szepesvari, and A.~Antos. \newblock Online {M}arkov decision processes under bandit feedback. \newblock In \emph{Advances in Neural Information Processing Systems (NIPS)}, 2010.}
}

@misc{ortner2012regret,
  note = {R.~Ortner, D.~Ryabko, P.~Auer, and R.~Munos. \newblock Regret bounds for restless {M}arkov bandits. \newblock \emph{arXiv preprint arXiv:1209.2693}, 2012.}
}

@misc{PR11,
  note = {V.~Perchet and P.~Rigollet. \newblock The multi-armed bandit problem with covariates. \newblock \emph{Arxiv preprint arXiv:1110.6084}, 2011.}
}

@misc{farias2006combining,
  note = {D.~Pucci~de Farias and N.~Megiddo. \newblock Combining expert advice in reactive environments. \newblock \emph{Journal of the ACM}, 53\penalty0 (5):\penalty0 762--799, 2006.}
}

@misc{Rak09,
  note = {A.~Rakhlin. \newblock Lecture notes on online learning. \newblock 2009.}
}

@misc{Rob52,
  note = {H.~Robbins. \newblock Some aspects of the sequential design of experiments. \newblock \emph{Bulletin of the American Mathematics Society}, 58:\penalty0 527--535, 1952.}
}

@misc{RM51,
  note = {H.~Robbins and S.~Monro. \newblock A stochastic approximation method. \newblock \emph{Annals of Mathematical Statistics}, 22:\penalty0 400--407, 1951.}
}

@misc{RT10,
  note = {P.~Rusmevichientong and J.~Tsitsiklis. \newblock Linearly parameterized bandits. \newblock \emph{Mathematics of Operations Research}, 35:\penalty0 395--411, 2010.}
}

@misc{SA11,
  note = {A.~Salomon and J.-Y. Audibert. \newblock Deviations of stochastic bandit regret. \newblock In \emph{Proceedings of the 22nd International Conference on Algorithmic Learning Theory (ALT)}, 2011.}
}

@misc{NIPS2011_0948,
  note = {Y.~Seldin, P.~Auer, F.~Laviolette, J.~Shawe-Taylor, and R.~Ortner. \newblock Pac-bayesian analysis of contextual bandits. \newblock In \emph{Advances in Neural Information Processing Systems (NIPS)}, 2011.}
}

@misc{Sha07,
  note = {S.~Shalev-Shwartz. \newblock \emph{Online Learning: Theory, Algorithms, and Applications}. \newblock PhD thesis, The Hebrew University of Jerusalem, 2007.}
}

@misc{slivkins2009contextual,
  note = {A.~Slivkins. \newblock Contextual bandits with similarity information. \newblock In \emph{Proceedings of the 24th Annual Conference on Learning Theory (COLT)}, JMLR Workshop and Conference Proceedings Volume 19, 2011.}
}

@misc{slivkins2008adapting,
  note = {A.~Slivkins and E.~Upfal. \newblock Adapting to a changing environment: The {B}rownian restless bandits. \newblock In \emph{Procedings of the 21st Annual Conference on Learning Theory (COLT)}, 2008.}
}

@misc{SST11,
  note = {N.~Srebro, K.~Sridharan, and A.~Tewari. \newblock On the universality of online {M}irror {D}escent. \newblock In \emph{Advances in Neural Information Processing Systems (NIPS)}, 2011.}
}

@misc{SKKS10,
  note = {N.~Srinivas, A.~Krause, S.M. Kakade, and M.~Seeger. \newblock {G}aussian process optimization in the bandit setting: no regret and experimental design. \newblock In \emph{Proceedings of the 27th International Conference on Machine Learning (ICML)}, 2010.}
}

@misc{Sto05,
  note = {G.~Stoltz. \newblock \emph{Incomplete Information and Internal Regret in Prediction of Individual Sequences}. \newblock PhD thesis, Universit\'e Paris-Sud, 2005.}
}

@misc{SB98,
  note = {R.S. Sutton and A.G. Barto. \newblock \emph{Reinforcement Learning: An Introduction}. \newblock MIT Press, 1998.}
}

@misc{Sze10,
  note = {C.~Szepesv{\'a}ri. \newblock \emph{Algorithms for Reinforcement Learning}. \newblock Morgan and Claypool, 2010.}
}

@misc{TW03,
  note = {E.~Takimoto and M.~Warmuth. \newblock Paths kernels and multiplicative updates. \newblock \emph{Journal of Machine Learning Research}, 4:\penalty0 773--818, 2003.}
}

@misc{TL11,
  note = {C.~Tekin and M.~Liu. \newblock Online learning of rested and restless bandits. \newblock \emph{IEEE Transactions on Information Theory}, 58\penalty0 (8):\penalty0 5588--5611, 2012.}
}

@misc{TT09,
  note = {F.~Teytaud and O.~Teytaud. \newblock Creating an upper-confidence-tree program for {H}avannah. \newblock In \emph{Advances in Computer Games}, pages 65--74, 2009.}
}

@misc{Tho33,
  note = {W.~Thompson. \newblock On the likelihood that one unknown probability exceeds another in view of the evidence of two samples. \newblock \emph{Bulletin of the American Mathematics Society}, 25:\penalty0 285--294, 1933.}
}

@misc{UNK10,
  note = {T.~Uchiya, A.~Nakamura, and M.~Kudo. \newblock Algorithms for adversarial bandit problems with multiple plays. \newblock In \emph{Proceedings of the 21st International Conference on Algorithmic Learning Theory (ALT)}, 2010.}
}

@misc{wald1947sequential,
  note = {A.~Wald. \newblock \emph{Sequential Analysis}. \newblock J.~Wiley and Sons, 1947.}
}

@misc{wang2005arbitrary,
  note = {C.C. Wang, S.R. Kulkarni, and H.V. Poor. \newblock Arbitrary side observations in bandit problems. \newblock \emph{Advances in Applied Mathematics}, 34\penalty0 (4):\penalty0 903--938, 2005{\natexlab{a}}.}
}

@misc{wang2005bandit,
  note = {C.C. Wang, S.R. Kulkarni, and H.V. Poor. \newblock Bandit problems with side observations. \newblock \emph{IEEE Transactions on Automatic Control}, 50\penalty0 (3):\penalty0 338--355, 2005{\natexlab{b}}.}
}

@misc{WAM08,
  note = {Y.~Wang, J.-Y. Audibert, and R.~Munos. \newblock Algorithms for infinitely many-armed bandits. \newblock In \emph{Advances in Neural Information Processing Systems (NIPS)}, 2008.}
}

@misc{WK08,
  note = {M.~Warmuth and D.~Kuzmin. \newblock Randomized online {PCA} algorithms with regret bounds that are logarithmic in the dimension. \newblock \emph{Journal of Machine Learning Research}, 9:\penalty0 2287--2320, 2008.}
}

@misc{WKH11,
  note = {M.~Warmuth, W.~Koolen, and D.~Helmbold. \newblock Combining initial segments of lists. \newblock In \emph{In Proceedings of the 22nd International Conference on Algorithmic Learning Theory (ALT)}, 2011.}
}

@misc{WS12,
  note = {Christopher~A. Wilkens and Balasubramanian Sivan. \newblock Single-call mechanisms. \newblock In \emph{ACM Conference on Electronic Commerce (EC)}, 2012.}
}

@misc{yu2011unimodal,
  note = {J.Y. Yu and S.~Mannor. \newblock Unimodal bandits. \newblock In \emph{Proceedings of the 28th International Conference on Machine Learning (ICML)}, 2011.}
}

@misc{YMS09,
  note = {J.Y. Yu, S.~Mannor, and N.~Shimkin. \newblock Markov decision processes with arbitrary reward processes. \newblock \emph{Mathematics of Operations Research}, 34:\penalty0 737--757, 2009.}
}

@misc{YJ11,
  note = {Y.~Yue and T.~Joachims. \newblock Beat the mean bandit. \newblock In \emph{Proceedings of the 28th International Conference on Machine Learning (ICML)}, 2011.}
}

@misc{YBKJ09,
  note = {Y.~Yue, J.~Broder, R.~Kleinberg, and T.~Joachims. \newblock The $k$-armed dueling bandits problem. \newblock In \emph{Proceedings of the 22nd Annual Conference on Learning Theory (COLT)}, 2009.}
}

@misc{Zin03,
  note = {M.~Zinkevich. \newblock Online convex programming and generalized infinitesimal gradient ascent. \newblock In \emph{Proceedings of the Twentieth International Conference on Machine Learning (ICML)}, 2003.}
}

